{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd3004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import random\n",
    "import fiona\n",
    "from shapely.geometry import Point\n",
    "from geopy.distance import geodesic\n",
    "from scipy.spatial import cKDTree\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import random, os, sys\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.insert(0, 'C:/Users/mmh/Documents/Codes/cross-sectro-transp-energy-model/')\n",
    "# importlib.reload(sys.modules['src.calculation'])\n",
    "from src.func_buildings import *\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "data_dir = 'C:/Users/mmh/Documents/Data/'\n",
    "data_dir2 = 'C:/Users/mmh/OneDrive - Oak Ridge National Laboratory/Melrose/9.Data/'\n",
    "map_dir = 'C:/Users/mmh/OneDrive - Oak Ridge National Laboratory/Melrose/8.Maps/'\n",
    "\n",
    "# %store -r building_cap\n",
    "# %store -r building_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea98dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "shp = gpd.read_file(map_dir + 'geo/tl_2021/tl_2021_13_bg.zip') # Georgia\n",
    "# shp = shp[(shp.STATEFP == '13')&(shp.COUNTYFP == '059')]\n",
    "shp = shp[(shp.STATEFP == '13')&(shp.COUNTYFP == '121')] # Fulton\n",
    "print(len(shp))\n",
    "shp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa867d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = shp.loc[(shp.STATEFP == '13')&(shp.COUNTYFP == '059'),'GEOID'].values\n",
    "od_application = od_long[(od_long.COUNTY_origin=='13059')&(od_long.COUNTY_dest=='13059')]  \n",
    "print(len(set(od_application.origin)))\n",
    "od_application.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a5264",
   "metadata": {},
   "source": [
    "# Trip chain generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e58be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trip_chain(init_o,num_veh,trajectory=[]):\n",
    "    for veh in range(1,num_veh+1):# Loop through all vehicles that start from this zone\n",
    "        print('vehicle id: '+str(veh))\n",
    "        #### step 2: number of trips in the trip chain\n",
    "        ntrips = 0\n",
    "        while ntrips <= 0: #select one value based on normal distribution\n",
    "            ntrips = int(np.random.normal(loc=ntrips_mean, scale=ntrips_std, size=1))\n",
    "        trip_id = 1\n",
    "        print('step 2 output: '+str(ntrips)+' trips in trip chain')\n",
    "        \n",
    "        while trip_id <= ntrips: \n",
    "            #### step 3: departure time (30 min granularity)          \n",
    "            if trip_id == 1:\n",
    "                start_time = np.random.choice(nhts_start_all[ntrips,trip_id].start_time, 1, \n",
    "                                            p=nhts_start_all[ntrips,trip_id].share)[0]\n",
    "                start_hour = int(start_time) \n",
    "                init_start_hour = start_hour\n",
    "                # Filter the OD data for the current hour\n",
    "                od_hour_df = od_application[od_application['hour'] == start_hour] # od application should be an input??\n",
    "                od_hour_df = od_hour_df[od_hour_df.origin == init_o] # initial starting point\n",
    "                start_zone = init_o\n",
    "            else:         \n",
    "                start_hour = int(departure_time) \n",
    "                start_time = departure_time                \n",
    "                # Filter the OD data for the current hour\n",
    "                od_hour_df = od_long[od_long['hour'] == start_hour]\n",
    "                od_hour_df = od_hour_df[od_hour_df.origin == next_zone] \n",
    "                start_zone = next_zone\n",
    "            print('step 3 output: '+str(start_time)+' departure. Start zone: '+str(start_zone))\n",
    "        \n",
    "            #### step 4: trip purpose\n",
    "            purpose_origin = np.random.choice(nhts_purpose_origin[ntrips,trip_id].loc[nhts_purpose_origin[ntrips,trip_id].start_time==start_time,\n",
    "                                                                                      'origin_purpose'], 1, \n",
    "                                p=nhts_purpose_origin[ntrips,trip_id].loc[nhts_purpose_origin[ntrips,trip_id].start_time==start_time,'share'])[0]   \n",
    "            purpose = np.random.choice(nhts_purpose_all[ntrips,trip_id].loc[nhts_purpose_all[ntrips,trip_id].start_time==start_time,\n",
    "                                                                            'purpose'], 1, \n",
    "                                p=nhts_purpose_all[ntrips,trip_id].loc[nhts_purpose_all[ntrips,trip_id].start_time==start_time,'share'])[0]   \n",
    "            print('step 4 output: '+str(purpose)+' trip purpose')\n",
    "                \n",
    "            #### step 5: possible destinations         \n",
    "            possible_zones = od_hour_df.copy()\n",
    "            \n",
    "            # Generate next zone\n",
    "            possible_zones['prob'] = possible_zones.trips/possible_zones.trips.sum()\n",
    "            prob = possible_zones['prob'].ravel()\n",
    "                   \n",
    "            next_zone = np.random.choice(possible_zones.destination.values, p=prob)\n",
    "            driving_dist = possible_zones.loc[(possible_zones.destination==next_zone),'dist'].values[0]         \n",
    "            avg_speed = 40 # miles per hour\n",
    "            driving_time = driving_dist/avg_speed\n",
    "            arrival_time = start_time + driving_time\n",
    "            print('step 6 output: '+str(next_zone)+' next zone')\n",
    "\n",
    "            #### step 7: determine next departure time and stay time\n",
    "            trip_id = trip_id + 1\n",
    "            if trip_id <= ntrips and arrival_time < 20 : # heuristic\n",
    "                departure_time = np.random.choice(nhts_start_all[ntrips,trip_id].start_time, 1, \n",
    "                                            p=nhts_start_all[ntrips,trip_id].share)[0]    \n",
    "                if departure_time <= arrival_time:\n",
    "                    departure_time = math.ceil(arrival_time * 2) / 2 \n",
    "                stay_time = departure_time - arrival_time # occupancy\n",
    "            else:\n",
    "                stay_time = 24-arrival_time + init_start_hour\n",
    "                if trip_id <= ntrips:\n",
    "                    ntrips = trip_id-1\n",
    "            print('step 7 output: '+str(stay_time)+' hours stay time')\n",
    "            \n",
    "            # save trajectory:\n",
    "            trip_info = [trip_id-1,veh,start_time,start_zone,purpose_origin,purpose,arrival_time,next_zone,driving_dist,avg_speed,stay_time]\n",
    "            trajectory.append(trip_info)\n",
    "\n",
    "    trajectory_df = pd.DataFrame(trajectory, columns=['trip_id','veh_id', 'start_time', 'start_zone', 'purpose_origin', 'purpose', 'arrival_time', 'end_zone','distance','avg_speed','stay_time'])\n",
    "    \n",
    "    # assign to building\n",
    "    trajectory_df = bg_to_building(trajectory_df)\n",
    "    return(trajectory_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68504140",
   "metadata": {},
   "source": [
    "# Application in Clark County to estiamte charging load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abbae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine base population based on census\n",
    "nhts_pov = nhts[nhts['TRPTRANS'].isin([3,4,5,6,8,9,18])] # POV\n",
    "nhts_pov = nhts_pov[nhts_pov['rank'] == 1]\n",
    "\n",
    "# bg pop\n",
    "zone_population = pd.read_csv(data_dir+'Census/ACSDT5Y2019.B01001 GA BG/ACSDT5Y2019.B01001-Data.csv')\n",
    "zone_population = zone_population.loc[1:,['GEO_ID','B01001_001E']]\n",
    "zone_population['GEO_ID'] = zone_population['GEO_ID'].str[9:]\n",
    "zone_population.columns = ['origin','pop']\n",
    "\n",
    "zone_population['COUNTY_origin'] = zone_population['origin'].str[:5]\n",
    "zone_population['pop'] = pd.to_numeric(zone_population['pop'])\n",
    "zone_population['origin'] = pd.to_numeric(zone_population['origin'])\n",
    "print(len(zone_population))\n",
    "zone_population.head()\n",
    "\n",
    "# county pop\n",
    "county_population = zone_population.groupby('COUNTY_origin').agg({'pop':'sum'}).reset_index()\n",
    "county_population.head()\n",
    "\n",
    "# calculate veh\n",
    "nhts_total = nhts_pov['WTTRDFIN'].sum()/365\n",
    "nhts_total_059 = nhts_total * county_population.loc[county_population.COUNTY_origin=='13059','pop'].values[0]/county_population['pop'].sum()\n",
    "bg_base = zone_population[zone_population.COUNTY_origin=='13059']\n",
    "print(len(bg_base))\n",
    "bg_base['base_veh'] = bg_base['pop']/bg_base['pop'].sum() * nhts_total_059\n",
    "bg_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6ef758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zones = shp.loc[(shp.STATEFP == '13')&(shp.COUNTYFP == '059'),'GEOID'].values\n",
    "# np.where(zones == '130590302003')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single processing\n",
    "zones = shp.loc[(shp.STATEFP == '13')&(shp.COUNTYFP == '121'),'GEOID'].values\n",
    "# zones = [130591406001]\n",
    "\n",
    "for i in range(len(zones)): # len(zones)\n",
    "    init_o = int(zones[i])\n",
    "    if os.path.isfile(os.path.join(data_dir, 'OD/Fulton County_v2/', 'trip_chain_' + str(init_o) + '.feather')):\n",
    "        continue\n",
    "    num_veh = 100\n",
    "    trajectory_df = generate_trip_chain(init_o,num_veh,trajectory=[])\n",
    "    trajectory_df.to_feather(data_dir+'OD/Fulton County_v2/trip_chain_'+str(init_o)+'.feather')\n",
    "    # v1: Buildings with high occ are removed\n",
    "    # v2: Keep all buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a889f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(zones == '131210082041')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb71dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2\n",
    "zones = shp.loc[(shp.STATEFP == '13')&(shp.COUNTYFP == '059'),'GEOID'].values\n",
    "# zones = [130591406001]\n",
    "for i in range(len(zones)): # \n",
    "    init_o = int(zones[i])\n",
    "    # base_veh = bg_base.loc[bg_base.origin==init_o,'base_veh']\n",
    "    # if len(base_veh)==0:\n",
    "    #     continue\n",
    "    # num_veh = int(bg_base.loc[bg_base.origin==init_o,'base_veh'].values[0])\n",
    "    # print(num_veh)\n",
    "    num_veh = 100\n",
    "    trajectory_df = generate_trip_chain(init_o,num_veh,trajectory=[])\n",
    "    # trajectory_df['init_o'] = i\n",
    "    trajectory_df.to_feather(data_dir+'OD/Clarke County_v3/trip_chain_'+str(init_o)+'.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
